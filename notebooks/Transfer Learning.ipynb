{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "Author: Braulio Otavalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import datadet from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tl_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/karakaggle/kaggle-cat-vs-dog-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 787M/787M [00:10<00:00, 79.7MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/codespace/.cache/kagglehub/datasets/karakaggle/kaggle-cat-vs-dog-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"karakaggle/kaggle-cat-vs-dog-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_dirs = ['/workspaces/transfer-learning/data/Cat', '/workspaces/transfer-learning/data/Dog']\n",
    "train_dirs = ['/workspaces/transfer-learning/data/train/Cat', '/workspaces/transfer-learning/data/train/Dog']\n",
    "validation_dirs = ['/workspaces/transfer-learning/data/validation/Cat', '/workspaces/transfer-learning/data/validation/Dog']\n",
    "\n",
    "# Create the destination directories if they don't exist\n",
    "for dir in train_dirs + validation_dirs:\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "# Function to split files into train and validation sets\n",
    "def split_files(source_dir, train_dir, validation_dir, split_ratio=0.8):\n",
    "    files = os.listdir(source_dir)\n",
    "    random.shuffle(files)\n",
    "    split_index = int(len(files) * split_ratio)\n",
    "    train_files = files[:split_index]\n",
    "    validation_files = files[split_index:]\n",
    "\n",
    "    for file in train_files:\n",
    "        shutil.move(os.path.join(source_dir, file), os.path.join(train_dir, file))\n",
    "    for file in validation_files:\n",
    "        shutil.move(os.path.join(source_dir, file), os.path.join(validation_dir, file))\n",
    "\n",
    "# Split the files for each category\n",
    "for source_dir, train_dir, validation_dir in zip(source_dirs, train_dirs, validation_dirs):\n",
    "    split_files(source_dir, train_dir, validation_dir)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Cat images in train: 9992\n",
      "Number of Dog images in train: 9976\n",
      "Number of Cat images in validation: 2499\n",
      "Number of Dog images in validation: 2494\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files(directory):\n",
    "    return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n",
    "\n",
    "categories = ['Cat', 'Dog']\n",
    "data_types = ['train', 'validation']\n",
    "\n",
    "for data_type in data_types:\n",
    "    for category in categories:\n",
    "        dir_path = f'/workspaces/transfer-learning/data/{data_type}/{category}'\n",
    "        num_files = count_files(dir_path)\n",
    "        print(f'Number of {category} images in {data_type}: {num_files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 03:10:54.371788: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-08 03:10:54.619914: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-08 03:10:54.740448: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738984255.077438   17213 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738984255.168880   17213 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-08 03:10:55.852863: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-08 03:11:01.091295: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-02-08 03:11:01.680354: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2025-02-08 03:11:01.749066: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2025-02-08 03:11:01.771192: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the VGG16 model pre-trained on ImageNet, without the top classification layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add new classification layers on top of the pre-trained model\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the new model\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19966 images belonging to 2 classes.\n",
      "Found 4993 images belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('/workspaces/transfer-learning/data/train', target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory('/workspaces/transfer-learning/data/validation', target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=10, validation_data=validation_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
